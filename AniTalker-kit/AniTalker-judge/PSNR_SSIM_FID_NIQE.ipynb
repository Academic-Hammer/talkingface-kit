{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\AniTalker_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Name          PSNR Score  SSIM Score  FID Score   NIQE Score  \n",
      "May.mp4             29.772568   0.652101    42.338212   5.151919    \n",
      "Jae-in.mp4          29.750509   0.630766    89.133744   6.13143     \n",
      "Lieu.mp4            30.694761   0.759348    30.025657   5.937247    \n",
      "Macron.mp4          30.332479   0.733842    28.131079   5.964817    \n",
      "Obama.mp4           30.766657   0.758716    37.66468    7.44125     \n",
      "Obama1.mp4          29.598956   0.68332     47.335445   6.626041    \n",
      "Obama2.mp4          30.605588   0.733553    30.716751   6.35921     \n",
      "Shaheen.mp4         30.629148   0.748107    19.622528   5.441265    \n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "from pytorch_msssim import ssim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pyiqa\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision import transforms\n",
    "import scipy.linalg as linalg\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 视频路径\n",
    "base_path = 'videos'\n",
    "raw_videos_path = f'{base_path}/raw'\n",
    "synthetic_videos_path = f'{base_path}/synthetic'\n",
    "\n",
    "# 视频列表\n",
    "video_names = [\n",
    "    'May.mp4', 'Jae-in.mp4', 'Lieu.mp4', 'Macron.mp4', 'Obama.mp4', \n",
    "    'Obama1.mp4', 'Obama2.mp4', 'Shaheen.mp4'\n",
    "]\n",
    "\n",
    "# 加载视频帧\n",
    "def load_video_frames(video_path):\n",
    "    reader = imageio.get_reader(video_path)\n",
    "    frames = [frame for frame in reader]\n",
    "    reader.close()  # 关闭reader释放资源\n",
    "    return frames\n",
    "\n",
    "# 调整视频尺寸\n",
    "def resize_video(generated_frames, standard_size):\n",
    "    resized_generated_frames = [cv2.resize(frame, (standard_size[1], standard_size[0])) for frame in generated_frames]\n",
    "    return resized_generated_frames\n",
    "\n",
    "# 计算PSNR\n",
    "def calculate_psnr(standard_frames, generated_frames):\n",
    "    psnr_values = []\n",
    "    for i in range(len(standard_frames)):\n",
    "        mse = np.mean((standard_frames[i] - generated_frames[i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr = float('inf')  # 对于完全相同的图像，PSNR为无穷大\n",
    "        else:\n",
    "            max_pixel = 255.0\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "        psnr_values.append(psnr)\n",
    "    return np.mean(psnr_values)\n",
    "\n",
    "# 计算SSIM\n",
    "def calculate_ssim(standard_frames, generated_frames):\n",
    "    ssim_values = []\n",
    "    for i in range(len(standard_frames)):\n",
    "        # 规范化帧数据到[0, 1]并转换为float32\n",
    "        standard_frame = torch.tensor(standard_frames[i]).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        generated_frame = torch.tensor(generated_frames[i]).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        ssim_val = ssim(standard_frame, generated_frame, data_range=1.0, size_average=True)  # 正确的data_range\n",
    "        ssim_values.append(ssim_val.item())\n",
    "    return np.mean(ssim_values)\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载预训练的Inception模型\n",
    "inception_model = inception_v3(pretrained=True).to(device).eval()\n",
    "\n",
    "# 定义一个函数来提取视频帧的特征，使用批量处理\n",
    "def extract_features(video_path, model, device, batch_size=16):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    batch = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "        batch.append(img)\n",
    "        \n",
    "        if len(batch) == batch_size:\n",
    "            with torch.no_grad():\n",
    "                batch_tensor = torch.cat(batch, dim=0)\n",
    "                features = model(batch_tensor)\n",
    "                frames.extend(features.cpu().numpy())\n",
    "            batch = []  # 重置批量\n",
    "        \n",
    "    # 处理剩余的帧\n",
    "    if batch:\n",
    "        with torch.no_grad():\n",
    "            batch_tensor = torch.cat(batch, dim=0)\n",
    "            features = model(batch_tensor)\n",
    "            frames.extend(features.cpu().numpy())\n",
    "    \n",
    "    cap.release()  # 释放视频捕获资源\n",
    "    return frames\n",
    "\n",
    "# 计算每个视频特征的均值和协方差\n",
    "def calculate_statistics(features):\n",
    "    mean = np.mean(features, axis=0)\n",
    "    cov = np.cov(features, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "# 使用FID公式计算两个视频特征分布之间的FID分数\n",
    "def calculate_fid(standard_mean, standard_cov, generated_mean, generated_cov):\n",
    "    # 计算均值差\n",
    "    mean_diff = standard_mean - generated_mean\n",
    "    # 计算协方差矩阵的平方根\n",
    "    cov_sqrt = linalg.sqrtm(standard_cov @ generated_cov)\n",
    "    \n",
    "    # 计算FID\n",
    "    fid = np.sum(mean_diff ** 2) + np.trace(standard_cov + generated_cov - 2 * cov_sqrt)\n",
    "    \n",
    "    # 检查是否出现NaN或负值\n",
    "    if np.isnan(fid) or fid < 0:\n",
    "        fid = 0  # 或者返回一个合理的默认值\n",
    "    return fid\n",
    "\n",
    "# 计算NIQE得分\n",
    "def calculate_niqe_score(frames):\n",
    "    niqe_metric = pyiqa.create_metric('niqe')\n",
    "    scores = []\n",
    "    for frame in frames:\n",
    "        frame_tensor = torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0).float() / 255.0  # 规范化到[0, 1]\n",
    "        score = niqe_metric(frame_tensor)\n",
    "        scores.append(score)\n",
    "    del niqe_metric  # 删除NIQE指标以释放资源\n",
    "    return torch.tensor(scores).mean().item()\n",
    "\n",
    "# 输出指标名作为表头，设置列宽\n",
    "header = \"Video Name\".ljust(20) + \"PSNR Score\".ljust(12) + \"SSIM Score\".ljust(12) + \"FID Score\".ljust(12) + \"NIQE Score\".ljust(12)\n",
    "print(header)\n",
    "\n",
    "# 循环处理每个视频\n",
    "for video_name in video_names:\n",
    "    path_standard_video = f'{raw_videos_path}/{video_name}'\n",
    "    path_generated_video = f'{synthetic_videos_path}/{video_name}'\n",
    "    \n",
    "    standard_frames = load_video_frames(path_standard_video)\n",
    "    generated_frames = load_video_frames(path_generated_video)\n",
    "    \n",
    "    # 检查尺寸是否一致，不一致则调整尺寸\n",
    "    if generated_frames[0].shape != standard_frames[0].shape:\n",
    "        generated_frames = resize_video(generated_frames, standard_frames[0].shape)\n",
    "    \n",
    "    psnr_score = round(calculate_psnr(standard_frames, generated_frames), 6)\n",
    "    ssim_score = round(calculate_ssim(standard_frames, generated_frames), 6)\n",
    "    \n",
    "    standard_features = extract_features(path_standard_video, inception_model, device)\n",
    "    generated_features = extract_features(path_generated_video, inception_model, device)\n",
    "    \n",
    "    standard_mean, standard_cov = calculate_statistics(standard_features)\n",
    "    generated_mean, generated_cov = calculate_statistics(generated_features)\n",
    "    \n",
    "    fid_score = round(calculate_fid(standard_mean, standard_cov, generated_mean, generated_cov), 6)\n",
    "    generated_niqe = round(calculate_niqe_score(generated_frames), 6)\n",
    "    \n",
    "    # 格式化输出，确保列对齐\n",
    "    row = f\"{video_name.ljust(20)}{psnr_score:<12}{ssim_score:<12}{fid_score:<12}{generated_niqe:<12}\"\n",
    "    print(row)\n",
    "    \n",
    "    # 释放不再需要的资源\n",
    "    del standard_frames, generated_frames, standard_features, generated_features\n",
    "    torch.cuda.empty_cache()  # 释放GPU缓存\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86188\\AppData\\Local\\Temp\\ipykernel_33716\\1210497081.py:29: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  mse = np.mean((standard_frames[i] - generated_frames[i]) ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR Score: 29.772568152345716\n",
      "SSIM Score: 0.6521003624369437\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     fid_value \u001b[38;5;241m=\u001b[39m calculate_fid(standard_images, generated_images)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fid_value\n\u001b[1;32m---> 63\u001b[0m fid_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandard_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFID Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 计算NIQE\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mcalculate_fid\u001b[1;34m(standard_frames, generated_frames)\u001b[0m\n\u001b[0;32m     58\u001b[0m standard_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m standard_frames]\n\u001b[0;32m     59\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m generated_frames]\n\u001b[1;32m---> 60\u001b[0m fid_value \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandard_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fid_value\n",
      "Cell \u001b[1;32mIn[1], line 58\u001b[0m, in \u001b[0;36mcalculate_fid\u001b[1;34m(standard_frames, generated_frames)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_fid\u001b[39m(standard_frames, generated_frames):\n\u001b[1;32m---> 58\u001b[0m     standard_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m standard_frames]\n\u001b[0;32m     59\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m generated_frames]\n\u001b[0;32m     60\u001b[0m     fid_value \u001b[38;5;241m=\u001b[39m calculate_fid(standard_images, generated_images)\n",
      "Cell \u001b[1;32mIn[1], line 58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_fid\u001b[39m(standard_frames, generated_frames):\n\u001b[1;32m---> 58\u001b[0m     standard_images \u001b[38;5;241m=\u001b[39m [\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m standard_frames]\n\u001b[0;32m     59\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mfromarray(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m generated_frames]\n\u001b[0;32m     60\u001b[0m     fid_value \u001b[38;5;241m=\u001b[39m calculate_fid(standard_images, generated_images)\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\AniTalker_judge\\lib\\site-packages\\PIL\\Image.py:3342\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3339\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires either tobytes() or tostring()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 3342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\AniTalker_judge\\lib\\site-packages\\PIL\\Image.py:3244\u001b[0m, in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3241\u001b[0m         im\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[1;32m-> 3244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\AniTalker_judge\\lib\\site-packages\\PIL\\Image.py:3181\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m decoder_args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m   3179\u001b[0m         decoder_args \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m-> 3181\u001b[0m     \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\AniTalker_judge\\lib\\site-packages\\PIL\\Image.py:882\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[1;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m    880\u001b[0m d \u001b[38;5;241m=\u001b[39m _getdecoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, decoder_name, decoder_args)\n\u001b[0;32m    881\u001b[0m d\u001b[38;5;241m.\u001b[39msetimage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim)\n\u001b[1;32m--> 882\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    885\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot enough image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'Image'"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "from pytorch_msssim import ssim\n",
    "import numpy as np\n",
    "\n",
    "# 视频路径\n",
    "path_standard_video = 'data-20241209T141743Z-001/data/raw/videos/May.mp4'\n",
    "path_generated_video = 'data-20241209T141743Z-001/data/synthetic/videos/May.mp4'\n",
    "\n",
    "# 加载视频\n",
    "def load_video_frames(video_path):\n",
    "    reader = imageio.get_reader(video_path)\n",
    "    frames = []\n",
    "    for frame in reader:\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "standard_frames = load_video_frames(path_standard_video)\n",
    "generated_frames = load_video_frames(path_generated_video)\n",
    "\n",
    "# 计算PSNR\n",
    "def calculate_psnr(standard_frames, generated_frames):\n",
    "    psnr_values = []\n",
    "    for i in range(len(standard_frames)):\n",
    "        mse = np.mean((standard_frames[i] - generated_frames[i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr = 100\n",
    "        else:\n",
    "            max_pixel = 255.0\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "        psnr_values.append(psnr)\n",
    "    return np.mean(psnr_values)\n",
    "\n",
    "psnr_score = calculate_psnr(standard_frames, generated_frames)\n",
    "\n",
    "print(f\"PSNR Score: {psnr_score}\")\n",
    "\n",
    "# 计算SSIM\n",
    "def calculate_ssim(standard_frames, generated_frames):\n",
    "    ssim_values = []\n",
    "    for i in range(len(standard_frames)):\n",
    "        standard_frame = torch.tensor(standard_frames[i]).permute(2, 0, 1).unsqueeze(0).float()\n",
    "        generated_frame = torch.tensor(generated_frames[i]).permute(2, 0, 1).unsqueeze(0).float()\n",
    "        ssim_val = ssim(standard_frame, generated_frame, data_range=255, size_average=True)\n",
    "        ssim_values.append(ssim_val.item())\n",
    "    return np.mean(ssim_values)\n",
    "\n",
    "ssim_score = calculate_ssim(standard_frames, generated_frames)\n",
    "\n",
    "print(f\"SSIM Score: {ssim_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: 52.521025925726924\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2  \n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 视频路径\n",
    "path_standard_video = 'data-20241209T141743Z-001/data/raw/videos/May.mp4'\n",
    "path_generated_video = 'data-20241209T141743Z-001/data/synthetic/videos/May.mp4'\n",
    "\n",
    "# 加载预训练的Inception模型\n",
    "inception_model = inception_v3(pretrained=True).to(device).eval()\n",
    "\n",
    "# 定义一个函数来提取视频帧的特征\n",
    "def extract_features(video_path, model, device):\n",
    "    # 视频帧提取和预处理\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = model(img)\n",
    "        frames.append(features.squeeze(0).cpu().numpy())\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# 从每个视频中提取帧并计算特征\n",
    "standard_frames = extract_features(path_standard_video, inception_model, device)\n",
    "generated_frames = extract_features(path_generated_video, inception_model, device)\n",
    "\n",
    "# 计算每个视频特征的均值和协方差\n",
    "def calculate_statistics(features):\n",
    "    mean = np.mean(features, axis=0)\n",
    "    cov = np.cov(features, rowvar=False)\n",
    "    return mean, cov\n",
    "\n",
    "standard_mean, standard_cov = calculate_statistics(standard_frames)\n",
    "generated_mean, generated_cov = calculate_statistics(generated_frames)\n",
    "\n",
    "# 使用FID公式计算两个视频特征分布之间的FID分数\n",
    "def calculate_fid(standard_mean, standard_cov, generated_mean, generated_cov):\n",
    "    # 计算均值差异\n",
    "    mean_diff = standard_mean - generated_mean\n",
    "    # 计算协方差矩阵差异\n",
    "    cov_diff = standard_cov + generated_cov - 2 * np.dot(standard_cov, generated_cov)\n",
    "    # 计算FID\n",
    "    fid = np.dot(mean_diff, mean_diff) + np.trace(cov_diff)\n",
    "    return fid\n",
    "\n",
    "fid_score = calculate_fid(standard_mean, standard_cov, generated_mean, generated_cov)\n",
    "print(f'FID score: {fid_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6074/6074 [08:01<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Video NIQE Score: 5.151919020330636\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pyiqa\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设定视频路径\n",
    "standard_video_path = 'data-20241209T141743Z-001/data/raw/videos/May.mp4'\n",
    "generated_video_path = 'data-20241209T141743Z-001/data/synthetic/videos/May.mp4'\n",
    "\n",
    "# 读取视频\n",
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# 计算NIQE得分\n",
    "def calculate_niqe_score(frames):\n",
    "    niqe_metric = pyiqa.create_metric('niqe')\n",
    "    scores = []\n",
    "    for frame in tqdm(frames):\n",
    "        # 将帧转换为张量\n",
    "        frame_tensor = torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        # 计算NIQE得分\n",
    "        score = niqe_metric(frame_tensor)\n",
    "        scores.append(score)\n",
    "    return torch.tensor(scores).mean().item()\n",
    "\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 读取视频帧\n",
    "    #standard_frames = read_video(standard_video_path)\n",
    "    generated_frames = read_video(generated_video_path)\n",
    "\n",
    "    # 计算NIQE得分\n",
    "    #standard_niqe = calculate_niqe_score(standard_frames)\n",
    "    generated_niqe = calculate_niqe_score(generated_frames)\n",
    "\n",
    "    # 输出评价得分\n",
    "    #print(f\"Standard Video NIQE Score: {standard_niqe}\")\n",
    "    print(f\"Generated Video NIQE Score: {generated_niqe}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AniTalker_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
