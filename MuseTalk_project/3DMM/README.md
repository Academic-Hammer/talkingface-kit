# 基于3DMM点云的TFG评价指标

在talking face generation领域，正确地评估生成的视频中人物动作、神态等身份信息对于提高生成质量有重要帮助，更有助于对于不同方法间的公平比较。传统的图像评价指标如psnr、ssim等并不能直接准确表示人物信息，可能受非人物的因素影响（如图像背景等）。对此，我们提出了一种全新的评价指标，通过抽取视频中的人脸点云信息，将生成的视频与Grand Truth进行对比，完成生成质量的评估。

###  评价方法

Deep3DFaceRecon 是一种使用CNN对人脸进行3D重建的方法，在重建速度、精确度、鲁棒性方面有了很大提升。它不仅能够完成对人脸的识别和提取关键点，还能够获取人物表情、动作等特征，用特征向量加以表示。![image-20241222024034296](C:\Users\14879\AppData\Roaming\Typora\typora-user-images\image-20241222024034296.png)

使用Deep3DFaceRecon方法抽取视频中人脸的关键点信息，得到  lm68 点云集。将生成视频与GT的关键点按照以下方式进行比较，进行标准化后根据MSE计算评价指标：
$$
\log(\sum_{i=1}^{68}\lambda_i[(x_i-\hat{x_i})^2+(y_i-\hat{y_i})^2]+m_i)
$$
其中，$(x,y)$ 代表点云的坐标，$\lambda_i$ 表示权重系数，可以据此对目标人物脸部的不同部位（如唇部、眼睛等）进行加权评估，以突出不同部位的渲染效果。$m_i$ 为偏移量。在下面的评测中，唇部位置 $\lambda _i=1.2$ 其余位置 $\lambda _i =1.0$ 。$m_i = 5$。

### 如何使用

1. 通过 ``pip install -r requirements`` 安装对应环境
2. 将需要对比的视频放置根目录，更改eval.py中的默认路径
3. 运行eval.py

### 评测结果

按照以上指标对测试集视频进行评测，结果如下：

| 视频    | MuseTalk(30s) | MuseTalk(half) |
| ------- | ------------- | -------------- |
| Jae-in  | 3.5845        | 3.5606         |
| Lieu    | 4.4873        | 4.3448         |
| Macron  | 5.0920        | 5.0923         |
| May     | 4.4909        | 4.5529         |
| Obama   | 4.3296        | 4.7277         |
| Obama1  | 4.8002        | 4.9230         |
| Obama2  | 4.5330        | 4.6687         |
| Shaheen | 3.8962        | 4.1104         |

